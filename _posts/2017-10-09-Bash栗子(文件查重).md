项目工程中无论是代码重构还是目录结构调整都可能会导致文件重复。因此查重是一大问题。

在Xcode中，如果引用上重复，可以通过编译发现。但是如果没有引用到工程文件，一个个查找会是相当痛苦的事情，写个脚本来处理将会大大节省人力。

#### 源代码
```
#!/bin/bash
# 此处查找后使用重定向命令，而不是用管道，是为了保证在子线程中能够修改count的值
#
#
count=0
find $1 -regex '.*\.[m,h,pch,xib]' > tmp.txt
while read line
do
# 字符串截取
    tmpStr=${line##*/}
    # echo 'tmpStr is ' $tmpStr
    lineNumber=$(find -P $1 -name $tmpStr | wc -l)
    if [[ $lineNumber -gt 1 ]]; then
        echo '--------重复的文件--------'
        find -P $1 -name $tmpStr
        echo '--------------------------'
        ((count++))
    fi

done < tmp.txt
echo "共计："$count"个重复文件"
rm -rf tmp.txt
```



#### 操作

创建脚本文件: `duplicateSearch.sh` 将上面代码复制到文件中。

终端执行命令

```
./duplicateSearch.sh 文件夹路径		# 是文件夹路径，可以将文件夹直接拖拽到终端即可
```



#### 完善一

* 统计文件名时会有重复的，那就直接对重复的文件名进行打印了
* Pods目录下的所有内容都不需要查找，可以直接忽略掉
* 如果Pods库没查找，抽离组件导致忘记移除不就无法查重了？ 后续优化

```
# !/bin/bash
# 如果tmp.txt存在，清空内容
echo ' ' > tmp.txt
find $1 -regex '.*\.[m,h,pch,xib]' | while read line 
do
# 如果路径中包含Pods不考虑，没有则写入临时文件
	if echo $line | grep 'Pods' >/dev/null 2>&1
	then
	echo -e ".\c"
	else
		tmpStr=${line##*/}
		echo $tmpStr >> tmp.txt
	fi
done
echo 'Pods文件夹过滤完成。。。。。。'
sort tmp.txt | uniq -d > tmp1.txt	#输出重复的文件名称
echo '初步计算共有'$(wc -l tmp1.txt | awk '{print $1'}) '个重复文件'
count=0
while read line 
do
	lineNumber=$(find -P $1 -name $line | wc -l)
	if [[ $lineNumber -gt 1 ]]; then
		echo '--------重复的文件--------'
        find -P $1 -name $line
        echo '--------------------------'
        ((count++))
	fi
done < tmp1.txt
echo "实际统计计："$count"个重复文件"
rm -rf tmp.txt
rm -rf tmp1.txt
```



#### 后续完善点

* 移除多余的文件， 需要根据xcproj文件引用取判断处理
* 如果Pods库没查找，抽离组件导致忘记移除不就无法查重了？ 后续优化



---

### 推荐一个库

synx，可以进行工程中虚拟文件夹实体化，还可以移除没有使用的资源文件。

<a href="https://github.com/linfengwenyou/synx.git" target="_blank">synx地址</a>